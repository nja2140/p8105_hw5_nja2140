---
title: "p8105_hw5_nja2140"
Author: Naina Ahuja
Assignment: Homework 5
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(rvest)

knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  fig.width = 8,
  fig.height = 6,
  out.width = "90%"
  )

set.seed(10)
```
Problem 1: Write a function that takes a vector as an argument; replaces missing values using the rules defined above; and returns the resulting vector. Apply this function to the columns of iris_with_missing using a map statement.

```{r}
iris_with_missing = iris %>% 
  map_df(~replace(.x, sample(1:150, 20), NA)) %>%
  mutate(Species = as.character(Species))
```
```{r}
fn_one = function(x){
  if(is.numeric(x) == TRUE){
    x = x %>% replace_na(mean(x, na.rm = TRUE))
  }
  if(is.character(x) == TRUE){
    x = x %>% replace_na("virginica")
  }
  
  return(x)
}

iris_with_missing = map_df(iris_with_missing, fn_one)
```
Problem 2: Create a tidy dataframe containing data from all participants, including the subject ID, arm, and observations over time:
-Start with a dataframe containing all file names; the list.files function will help
-Iterate over file names and read in data for each subject using purrr::map and saving the result as a new variable in the dataframe
-Tidy the result; manipulate file names to include control arm and subject ID, make sure weekly observations are “tidy”, and do any other tidying that’s necessary

```{r}
tidy_df = list.files(path="./data", full.names = TRUE) %>% 
  map(read.csv) %>% 
  rbind_all() %>% 
  mutate(
    subject_id = c(1:20),
    treatment_arm = ifelse(subject_id == c(1:10), "control", "experimental")
  ) %>% 
  select(subject_id, treatment_arm, everything())
```
Make a spaghetti plot showing observations on each subject over time, and comment on differences between groups.

```{r}
plot_one = 
  tidy_df %>% 
  pivot_longer(
    week_1:week_8,
    names_to = "week", 
    values_to = "observation"
  ) %>% 
  ggplot(aes(x = week, y = observation, color = treatment_arm, group=subject_id)) +
         geom_point() + geom_line() +
  labs(
  title = "Observation value over time per subject",
  x = "Week Number",
  y = "Observation"
  )
plot_one
```
Over time, the experimental arm has higher values throughout, even though both arms started around the same value at week 1. 

Problem 3: First set the following design elements:
-Fix n=30
-Fix xi1 as draws from a standard Normal distribution
-Fix β0=2
-Fix σ2=50
Set β1=0. Generate 10000 datasets from the model yi=β0+β1xi1+ϵi with ϵi∼N[0,σ2]. For each dataset, save β̂ 1 and the p-value arising from a test of H:β1=0 using α=0.05. Hint: to obtain the estimate and p-value, use broom::tidy to clean the output of lm.

```{r}
set.seed(1)
sim_regression = function(n=30, beta0 = 2, beta1 = 0) {
  sim_data = tibble(
    x = rnorm(n, mean = 0, sd =1), 
    y = beta0 + beta1 * x +rnorm(n, 0, sqrt(50))
  )
  
  ls_fit = lm(y ~ x, data=sim_data) %>% 
    broom::tidy()
  
  tibble(
    beta1_hat =ls_fit[[2,2]],
    beta1_p = ls_fit[[2,5]]
  )
}
```
```{r}
sim_results = rerun(10000, sim_regression(beta1 = 0)) %>% 
  bind_rows()
```
Repeat the above for β1={1,2,3,4,5,6}, and complete the following
-Make a plot showing the proportion of times the null was rejected (the power of the test) on the y axis and the true value of β2 on the x axis. Describe the association between effect size and power.
-Make a plot showing the average estimate of β̂ 1 on the y axis and the true value of β1 on the x axis. Make a second plot (or overlay on the first) the average estimate of β̂ 1 only in samples for which the null was rejected on the y axis and the true value of β1 on the x axis. Is the sample average of β̂ 1 across tests for which the null is rejected approximately equal to the true value of β1? Why or why not?

```{r}
sim_again =  
  tibble(beta1_2 = c(1,2,3,4,5,6)) %>% 
  mutate(
    output_lists =  map(.x = beta1_2, ~rerun(10000, sim_regression(beta1 = .x))),
    estimate_dfs = map(output_lists, bind_rows)) %>% 
  select(-output_lists) %>% 
  unnest(estimate_dfs)
```
```{r}
sim_again %>% 
  mutate(reject_H0 = as.numeric(ifelse(beta1_p<= 0.05, "1", "0"))) %>% 
  group_by(beta1_2) %>% 
  summarize(power = mean(reject_H0)) %>% 
  ggplot(aes(x = beta1_2, y = power)) +
  geom_point() + 
  geom_line() +
  labs(
  title = "Association between effect size and power",
  x = "True value of Beta2",
  y = "Power of the test"
  )
```
From the plot, we can see that the relationship between effect size and power is directly proportional. As effect size increases, power also increases.

```{r}
sim_again %>% 
  group_by(beta1_2) %>% 
  summarize(avg_beta1hat = mean(beta1_hat)) %>% 
  ggplot(aes(x = beta1_2, y = avg_beta1hat)) +
  geom_point() + 
  geom_line() +
  labs(
  title = "True value of Beta1 vs average estimate of Beta1",
  x = "True value of Beta1",
  y = "Average estimate of Beta1"
  )
```
```{r}
sim_again %>% 
  mutate(reject_H0 = as.numeric(ifelse(beta1_p<= 0.05, "1", "0"))) %>% 
  filter(reject_H0 == 1) %>% 
  group_by(beta1_2) %>% 
  summarize(avg_beta1hat = mean(beta1_hat)) %>% 
  ggplot(aes(x = beta1_2, y = avg_beta1hat)) +
  geom_point() + 
  geom_line() +
  labs(
  title = "True value of Beta1 vs average estimate of Beta1 in rejected H0 samples",
  x = "True value of Beta2",
  y = "Power of the test"
  )
```

